# AI_Project
DX-3 AI Class Project

# Gesture Impact Vision ğŸ¥

## ğŸ§© Project Overview
Real-time gesture detection using Vision AI that triggers visual effects on the camera feed.

## ğŸ¯ Objective
To develop an AI-based gesture control system that uses body movements as input switches for interactive visual effects.

## ğŸ”§ Key Technologies
- Openvino
- TensorFlow / Keras
- OpenCV (real-time video processing)
- Python (main control logic)

## ğŸ§  How It Works
1. Capture live camera feed.
2. Detect body landmarks.
3. Classify gestures.
4. Trigger mapped visual effect.

## ğŸ—“ï¸ Project Timeline
| Phase | Goal | Duration |
|-------|------|----------|
| 1 | Model Select | 1 |
| 2 | Gesture Training and Effect System |  2 |
| 3 | Integration | 3 |
| 4 | Demo & Docs | 4 |

## ğŸ‘¥ Team Members
| Role | Name | Description |
|------|------|-------------|
| PM | Park Sangsu | Planning / Coordination |
| AI Engineer | Cho Kyungwon | Model Design |
| Vision Engineer | Kim JunHyun | Video Stream Processing |
| Effect Designer | Beak Dabin, Jung Kungjun | Visual Effects |

